{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 13:24:28.314882: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-06 13:24:31.325752: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-06 13:24:31.351755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 13:24:38.484820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH =  50\n",
    "MAX_CURRENCY_FLAG = 2\n",
    "MAX_SPAM_WORDS = 1\n",
    "MAX_EMOJI = 2\n",
    "MAX_CONATANS = 1\n",
    "MAX_EMAIL= 1\n",
    "MAX_PHONE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RemoveStopWordsPunctuation:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __remove_punctuation_stopwords(self, text):\n",
    "        pattern = re.compile(\"[{}]\".format(re.escape(\"!\\\"#&'()*,-/:;<=>?[\\\\]^_`{|}~\")))\n",
    "        text = \" \".join(\n",
    "            [\n",
    "                word.strip()\n",
    "                for word in pattern.sub(\" \", text.lower()).split()\n",
    "                if word not in set(stopwords.words(\"english\"))\n",
    "            ]\n",
    "        )\n",
    "        return text\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"Comment\"] = df[\"Comment\"].apply(self.__remove_punctuation_stopwords)\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddLengthFlag:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[\"length\"] = X[\"Comment\"].str.len().astype(np.float32) / MAX_LENGTH\n",
    "        return X\n",
    "\n",
    "\n",
    "class AddCurrencyFlag:\n",
    "    def __init__(self) -> None:\n",
    "        self.currency_symbols = [\"â‚¤\", \"â‚¨\", \"â‚¬\", \"â‚¹\", \"â‚¿\", \"$\"]\n",
    "        self.pattern = \"([\\$â‚¤â‚¨â‚¬â‚¹â‚¿]+ *[0-9]* *[\\.,]?[0-9]*)|([0-9]* *[\\.,]?[0-9]* *[\\$â‚¤â‚¨â‚¬â‚¹â‚¿]+)\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_currency_count(self, text):\n",
    "        return len(re.findall(self.pattern, text)) / MAX_CURRENCY_FLAG\n",
    "\n",
    "    # def __add_currency_count(self,text):\n",
    "    #     return sum(text.count(symbol) for symbol in self.currency_symbols )\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"currency\"] = df[\"Comment\"].apply(self.__add_currency_count).astype(np.float32)\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddSpamWordsFlag:\n",
    "    def __init__(self) -> None:\n",
    "        self.spam_words = [\n",
    "            \"morning\",\n",
    "            \"good\"\n",
    "            \"urgent\",\n",
    "            \"exclusive\",\n",
    "            \"limited time\",\n",
    "            \"free\",\n",
    "            \"guaranteed\",\n",
    "            \"act now\",\n",
    "            \"discount\",\n",
    "            \"special offer\",\n",
    "            \"prize\",\n",
    "            \"instant\",\n",
    "            \"cash\",\n",
    "            \"save\",\n",
    "            \"win\",\n",
    "            \"best\",\n",
    "            \"secret\",\n",
    "            \"incredible\",\n",
    "            \"congratulations\",\n",
    "            \"approved\",\n",
    "            \"risk free\",\n",
    "            \"hidden\",\n",
    "            \"bonus\",\n",
    "            \"sale\",\n",
    "            \"amazing\",\n",
    "            \"extra cash\",\n",
    "            \"opportunity\",\n",
    "            \"easy\",\n",
    "            \"double your\",\n",
    "            \"best price\",\n",
    "            \"cash back\",\n",
    "            \"deal\",\n",
    "            \"earn\",\n",
    "            \"money\",\n",
    "            \"no obligation\",\n",
    "            \"profit\",\n",
    "            \"results\",\n",
    "            \"exciting\",\n",
    "            \"unbelievable\",\n",
    "            \"jackpot\",\n",
    "            \"fantastic\",\n",
    "            \"instant access\",\n",
    "            \"million dollars\",\n",
    "            \"discounted\",\n",
    "            \"last chance\",\n",
    "            \"exclusive offer\",\n",
    "            \"big savings\",\n",
    "            \"limited offer\",\n",
    "            \"free trial\",\n",
    "            \"special promotion\",\n",
    "            \"secret revealed\",\n",
    "            \"valuable\",\n",
    "            \"money-back guarantee\",\n",
    "            \"lowest price\",\n",
    "            \"save money\",\n",
    "            \"make money\",\n",
    "            \"no risk\",\n",
    "            \"exclusive deal\",\n",
    "            \"limited supply\",\n",
    "            \"huge\",\n",
    "            \"incredible offer\",\n",
    "            \"prize winner\",\n",
    "            \"earn extra income\",\n",
    "            \"limited spots\",\n",
    "            \"new offer\",\n",
    "            \"best deal\",\n",
    "            \"don't miss out\",\n",
    "            \"great savings\",\n",
    "            \"top offer\",\n",
    "            \"double your income\",\n",
    "            \"discount code\",\n",
    "            \"fast cash\",\n",
    "            \"top-rated\",\n",
    "            \"best value\",\n",
    "            \"no cost\",\n",
    "            \"elite\",\n",
    "            \"act fast\",\n",
    "            \"unbeatable\",\n",
    "            \"cash prize\",\n",
    "            \"limited availability\",\n",
    "            \"special discount\",\n",
    "            \"quick cash\",\n",
    "            \"no catch\",\n",
    "            \"instant approval\",\n",
    "            \"big discount\",\n",
    "            \"easy money\",\n",
    "            \"insider\",\n",
    "            \"invitation\",\n",
    "            \"free shipping\",\n",
    "            \"huge discount\",\n",
    "            \"extra income\",\n",
    "            \"secret formula\",\n",
    "            \"no strings attached\",\n",
    "            \"money-making\",\n",
    "            \"dream come true\",\n",
    "            \"massive\",\n",
    "            \"free gift\",\n",
    "            \"incredible opportunity\",\n",
    "            \"risk-free trial\",\n",
    "            \"instant money\",\n",
    "            \"special price\",\n",
    "            \"no purchase necessary\",\n",
    "            \"now\",\n",
    "        ]\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_currency_count(self, text):\n",
    "        return float(sum(text.count(symbol) for symbol in self.spam_words) / MAX_SPAM_WORDS)\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"spam_word\"] = df[\"Comment\"].apply(self.__add_currency_count).astype(np.float32)\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddEmojiFlag:\n",
    "    def __init__(self) -> None:\n",
    "        self.emoji_symbols = \"[ğŸ’­|ğŸ”|ğŸ†—|ğŸ‰|ğŸŠ|ğŸ“¯|ğŸ™Œ|ğŸ˜‚|ğŸ’¸|ğŸ‘‰|ğŸ“¢|ğŸš€|ğŸ’²|ğŸ’£|ğŸ”±|ğŸ’¼|ğŸ†™|â³|âœ¨|ğŸ’Œ|ğŸ’|ğŸ†•|ğŸ”|ğŸ’¡|ğŸ’°|ğŸ‘‘|â­|ğŸŒŸ|ğŸ¤|âš¡|ğŸ“ˆ|ğŸ’µ|ğŸ†|ğŸ’ª|ğŸ”“|ğŸ†“|ğŸ°|âŒš|ğŸš¨|ğŸ’¢|ğŸ“®|ğŸ”¥|ğŸˆ|ğŸ¥|ğŸ””|ğŸ’¯|ğŸ¶|ğŸ”—|ğŸ|ğŸ“š|ğŸ”Š|ğŸ‘|ğŸ‘|ğŸ“±|ğŸ“|ğŸ¤‘|ğŸ…|ğŸ”’|ğŸ“£|ğŸ’¥]\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_currency_count(self, text):\n",
    "        return float(len(re.findall(self.emoji_symbols, text)) / MAX_EMOJI)\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"emoji\"] = df[\"Comment\"].apply(self.__add_currency_count).astype(np.float32)\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddContainFlag:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_first_count(self, text):\n",
    "        pattern = \"[0-9]*%|T&C\"\n",
    "        return len(re.findall(pattern, text))\n",
    "\n",
    "    def __add_second_count(self, text):\n",
    "        pattern = \"(https:\\/\\/www\\.|http:\\/\\/www\\.|https:\\/\\/|http:\\/\\/)?[a-zA-Z0-9]{2,}(\\.[a-zA-Z0-9]{2,})(\\.[a-zA-Z0-9]{2,})?\"\n",
    "        return len(re.findall(pattern, text))\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"contain\"] = df[\"Comment\"].apply(self.__add_first_count)\n",
    "        df[\"contain\"] = df[\"contain\"] + df[\"Comment\"].apply(self.__add_second_count)\n",
    "        df['contain'] = df['contain'].astype(np.float32) / MAX_CONATANS\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddEmailFlag:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_email_count(self, text):\n",
    "        pattern = \"[\\w]+@[\\w]+\\.\\w+\"\n",
    "        return float(len(re.findall(pattern, text))  /MAX_EMAIL)\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"email\"] = df[\"Comment\"].apply(self.__add_email_count).astype(np.float32)\n",
    "        return df\n",
    "\n",
    "\n",
    "class AddPhoneFlag:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __add_phone_no_count(self, text):\n",
    "        pattern = \"\\+?[0-9]?[0-9]? ?0?[0-9]{10}\"\n",
    "        return len(re.findall(pattern, text))\n",
    "\n",
    "    def __add_phone_no_count_1(self, text):\n",
    "        pattern = \"\\+?[0-9]?\\d{3}[ -]?\\d{3}[ -]?\\d{4}\"\n",
    "        return len(re.findall(pattern, text))\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"phone\"] = df[\"Comment\"].apply(self.__add_phone_no_count)\n",
    "        df[\"phone\"] = df[\"phone\"] + df[\"Comment\"].apply(self.__add_phone_no_count_1)\n",
    "        df[\"phone\"] = df[\"phone\"].astype(np.float32) / MAX_PHONE\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class RemovePhoneLinkEmail:\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def __remove(self, text):\n",
    "        text = re.sub(\"\\$[0-9]*([\\.,][0-9]{2})*\\$?\", \"\", text)\n",
    "        text = re.sub(\"\\+?[0-9]?[0-9]? ?0?[0-9]{10}\", \"\", text)\n",
    "        text = re.sub(\"\\+?[0-9]?\\d{3}[ -]?\\d{3}[ -]?\\d{4}\", \"\", text)\n",
    "        text = re.sub(\n",
    "            r\"(https:\\/\\/www\\.|http:\\/\\/www\\.|https:\\/\\/|http:\\/\\/)?[a-zA-Z0-9]{2,}(\\.[a-zA-Z0-9]{2,})(\\.[a-zA-Z0-9]{2,})?\",\n",
    "            \"\",\n",
    "            text,\n",
    "        )\n",
    "        text = re.sub(r\"[\\w]+@[\\w]+\\.\\w+\", \"\", text)\n",
    "        text = emoji.replace_emoji(text)\n",
    "        return text\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"Comment\"] = df[\"Comment\"].apply(self.__remove)\n",
    "        return df\n",
    "\n",
    "\n",
    "class LemmatizeText:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def __lemmatize_text(self, text):\n",
    "        return \" \".join(\n",
    "            [self.lemmatizer.lemmatize(word) for word in re.split(\"\\W+\", text)]\n",
    "        ).strip()\n",
    "\n",
    "    def transform(self, df):\n",
    "        df[\"Comment\"] = df[\"Comment\"].map(lambda text: self.__lemmatize_text(text))\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "pipe =  Pipeline([\n",
    "    \n",
    "    (\"AddCurrencyFlag\",AddCurrencyFlag()),\n",
    "    (\"AddSpamWordsFlag\",AddSpamWordsFlag()),\n",
    "    (\"AddEmojiFlag\",AddEmojiFlag()),\n",
    "    (\"AddContainFlag\",AddContainFlag()),\n",
    "    (\"AddEmailFlag\",AddEmailFlag()),\n",
    "    (\"AddPhoneFlag\",AddPhoneFlag()),\n",
    "\n",
    "    (\"RemovePhoneLinkEmail\",RemovePhoneLinkEmail()),\n",
    "    (\"RemoveStopWordsPunctuation\",RemoveStopWordsPunctuation()),\n",
    "    \n",
    "    (\"LemmatizeText\",LemmatizeText()),\n",
    "\n",
    "    (\"AddLengthFlag\",AddLengthFlag()),\n",
    "    \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/spam-model.h5', custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precidt(msg):\n",
    "    if type(msg) is str:\n",
    "        df = pd.DataFrame([msg],columns=[\"Comment\"])\n",
    "    elif type(msg) is list:\n",
    "        df = pd.DataFrame(msg,columns=[\"Comment\"])\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    df = pipe.transform(df)\n",
    "    table = df\n",
    "    df = {\n",
    "        \"Comment\": tf.convert_to_tensor(df[\"Comment\"],dtype=tf.string),\n",
    "        \"Length\": tf.convert_to_tensor(df[\"length\"], dtype=tf.float32),\n",
    "        \"Currency\": tf.convert_to_tensor(df[\"currency\"], dtype=tf.float32),\n",
    "        \"Spam Words\": tf.convert_to_tensor(df[\"spam_word\"], dtype=tf.float32),\n",
    "        \"Emoji\": tf.convert_to_tensor(df[\"emoji\"], dtype=tf.float32),\n",
    "        \"Contain\": tf.convert_to_tensor(df[\"contain\"], dtype=tf.float32),\n",
    "        \"Email\": tf.convert_to_tensor(df[\"email\"], dtype=tf.float32),\n",
    "        \"Phone\": tf.convert_to_tensor(df[\"phone\"], dtype=tf.float32)\n",
    "    }\n",
    "    return [ \"{:.2f}% spam\".format(i *100)   for i in model.predict(df).reshape(-1,) ],table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['99.91% spam', '83.28% spam', '99.99% spam'],\n",
       "                 Comment  currency  spam_word  emoji  contain  email  phone   \n",
       " 0       good click free       0.0        1.0    0.0      1.0    0.0    0.0  \\\n",
       " 1        dadasdadasdsad       0.0        0.0    0.0      0.0    0.0    0.0   \n",
       " 2  brijeshkrishna click       0.0        0.0    0.0      1.0    1.0    0.0   \n",
       " \n",
       "    length  \n",
       " 0    0.30  \n",
       " 1    0.28  \n",
       " 2    0.40  )"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precidt([\"good click here https://dasda.asdsa free\",\"dadasdadasdsad\",\"brijeshkrishna@gmail.com click here\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
